{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V28",
      "collapsed_sections": [
        "Q7GHSNwPjbKG",
        "LId7UNRcjoGs",
        "oXZ6YM_AloCT",
        "Ig8xeTT3nSF8"
      ],
      "authorship_tag": "ABX9TyONkbdhhgr7e6lEuW3bAuJ2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adikeshn/Alzheimer-MRI-Classification/blob/main/Alzheimers_MRI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading Libraries and the MRI image data"
      ],
      "metadata": {
        "id": "Q7GHSNwPjbKG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nliyLpY502VE"
      },
      "outputs": [],
      "source": [
        "!pip install q kaggle\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import autoviz\n",
        "import seaborn as sns\n",
        "import os\n",
        "import random\n",
        "import matplotlib.pylab as plt\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "JZHlAYlA1BwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.upload()"
      ],
      "metadata": {
        "id": "3_3tG8-11D28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d uraninjo/augmented-alzheimer-mri-dataset\n",
        "! unzip /content/augmented-alzheimer-mri-dataset.zip"
      ],
      "metadata": {
        "id": "_ytxLjYb1Qbk",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "LId7UNRcjoGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Getting the images from each folder and putting them in an array\n",
        "\n",
        "\n",
        "*   Same amount of images per classification in the array (prevents model bias toward one classification)\n",
        "*   Setting the max-height and max-width variable for later use in image processing\n",
        "\n"
      ],
      "metadata": {
        "id": "Q42mzoLjju90"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "classificationID = 0\n",
        "images = []\n",
        "labels = []\n",
        "first = []\n",
        "max_height = 0\n",
        "max_width = 0\n",
        "\n",
        "for folder in os.listdir(\"AugmentedAlzheimerDataset\"):\n",
        "  folder_path = os.path.join(\"AugmentedAlzheimerDataset\", folder)\n",
        "  num_images = 0\n",
        "  for file in os.listdir(folder_path):\n",
        "    image_path = os.path.join(folder_path, file)\n",
        "    image = plt.imread(image_path)\n",
        "    height, width, _ = image.shape\n",
        "    max_height = max(max_height, height)\n",
        "    max_width = max(max_width, width)\n",
        "    first.append([image, classificationID])\n",
        "    num_images += 1\n",
        "    if num_images == 6400:\n",
        "      break\n",
        "\n",
        "  classificationID += 1\n",
        "\n",
        "random.shuffle(first)\n",
        "\n",
        "for data in first:\n",
        "  images.append(data[0])\n",
        "  labels.append([data[1]])"
      ],
      "metadata": {
        "id": "jtJd2maW1_PJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "*   Compress: compresses each image passed into it by first adding padding to make each image to make all of them the same size, making the image grayscale to reduce unneccesary color information by averaging the RGB values and reducing the dimensions of the image array to 2, and making each value in the array be between 0-1\n",
        "*   predict: predicts what classification an image belongs to using the model\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RYzuHHdpkQvs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compress(image):\n",
        "  resized_image = tf.image.resize_with_pad(image, max_height, max_width)\n",
        "  grayscale_images = np.mean(resized_image, axis=2)\n",
        "  normalized_image = np.array((grayscale_images - np.min(grayscale_images)) / (np.max(grayscale_images) - np.min(grayscale_images)))\n",
        "\n",
        "  zero_filtered = np.where(normalized_image <= 0.033, 0, normalized_image)\n",
        "  return zero_filtered\n",
        "\n",
        "def predict(image, compressed):\n",
        "  if not compressed:\n",
        "    image = compress(image)\n",
        "  predictions = model.predict(image.reshape(1, max_height, max_width, 1), verbose = 0)\n",
        "  return np.argmax(predictions)\n",
        "\n",
        "def Id_to_classification(id):\n",
        "  if id == 0:\n",
        "    return \"MildDementia\"\n",
        "  elif id == 1:\n",
        "    return \"ModerateDementia\"\n",
        "  elif id == 2:\n",
        "    return \"NonDementia\"\n",
        "  elif id == 3:\n",
        "    return \"VeryMildDementia\"\n",
        "\n"
      ],
      "metadata": {
        "id": "G3kkJJ37lMZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compressing each image and adding them into a new array"
      ],
      "metadata": {
        "id": "XFxxlXM0lgIx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "compressed_images = []\n",
        "for image in images:\n",
        "  compressed_images.append(compress(image))\n",
        "\n",
        "\n",
        "compressed_images = np.array(compressed_images)\n",
        "labels = np.array(labels)\n"
      ],
      "metadata": {
        "id": "qzPVYcDB5Lay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting the dataset into training and testing"
      ],
      "metadata": {
        "id": "pC941Zidlu2d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_test_split_ratio = 0.9\n",
        "\n",
        "num_data = labels.shape[0]\n",
        "train_size = int(num_data * train_test_split_ratio)\n",
        "\n",
        "train_images = zero_filtered[:train_size]\n",
        "train_labels = labels[:train_size]\n",
        "test_images = zero_filtered[train_size:]\n",
        "test_labels = labels[train_size:]\n",
        "\n",
        "train_images = train_images.reshape((train_images.shape[0], 190, 200, 1))\n",
        "test_images = test_images.reshape((test_images.shape[0], 190, 200, 1))\n",
        "\n",
        "train_images = train_images.astype('float32')\n",
        "test_images = test_images.astype('float32')"
      ],
      "metadata": {
        "id": "5df8KmLp7Yk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating the Model"
      ],
      "metadata": {
        "id": "oXZ6YM_AloCT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I am using a CNN model to classify the images, with 3 CNN layers and 3 pooling layers, followed by a dense layer and a dropout to reduce overfitting"
      ],
      "metadata": {
        "id": "4yUUe_3Gl1ax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(16, (3, 3), activation='relu', input_shape=(190, 200, 1)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(4)\n",
        "])"
      ],
      "metadata": {
        "id": "vBeiWLBI8KoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "4ZTq0n3IjtIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_images, train_labels, epochs=7,\n",
        "                    validation_data=(test_images, test_labels))"
      ],
      "metadata": {
        "id": "erjGFj6Wjt-H",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing the Model"
      ],
      "metadata": {
        "id": "Ig8xeTT3nSF8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for index in range(len(test_images)):\n",
        "  print(f\"True: {Id_to_classification(test_labels[index])} Predicted: {Id_to_classification(predict(test_images[index], True))}\")\n",
        "  plt.imshow(test_images[index].reshape(max_height, max_width))\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "O5NZpScumlk9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}